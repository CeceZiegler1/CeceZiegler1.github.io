{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3ed98647-4d20-4809-a19a-b2a7677d67bf",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning From Timnit Gebru\n",
    "author: Cece Ziegler\n",
    "date: '2023-04-16'\n",
    "description: \"This blog post illustrates my implementation of singular value decomposition of an image using unsupervised learning.\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3104cf1-150a-49af-bf9c-08ea509b2a90",
   "metadata": {},
   "source": [
    "# Learning From Timnit Gebru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1e7b0-a90c-4e9a-9665-51a39a2bedb2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Timnit Gebru grew up in Ethipoia and moved to the United States when she was 15 to flee the Eritrean-Ethiopian war. After experiencing difficulties with being allowed to live in the United States, Gebru finally settled in Sommerville Massachusetts where she attended high school. Gebru is an incrediblly influential and important figure due to her work regarding algorithmic bias in machine learning algorithms, specifically within computer vision. Through many experiences of racial bias Gebru has faced personally, she is passionate and knowelgeable on the topic. After working for world renowned tech companies including Apple and Google, Gebru has expressed the mistreatment and bias she has seen within these big tech companies. African Americans are mis-identified by computer vision technologies at a disproportionate rate. After writing a research paper for Google that detailed the potential negative effects of a new AI technology, a paper she was asked to write, Gebru left google as higher up athorities were not happy with what she wrote and didn't want the paper published. After the poor experience with Google, Gebru doesn't have much intrest in returning to work for a big tech company. Instead, she has started her own research intiative, Black in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d033fb-aed5-4ccd-aed5-526908d695bc",
   "metadata": {},
   "source": [
    "# Dr. Gebru's Talk\n",
    "In the talk from Dr. Gebru, she addresses issues of fairness and ethics in technology, specifically computer vision. One of the main points Dr. Gebru brings up is how technology has done harm to black people and how black people, especially black women are under represented in the technology field. Although she mentions how technology as a whole has done harm to the black community, she speficially focusses on computer vision. Computer vision is a dangerous technology and we don't know what it is being used for. Gebru brings up many applications that use computer vision technology in unethical way. For example, one app, Faception, profilies people based on their facial image. Other companies use facial deetction softwares during interviews in an attempt to track candidates non verbal responses and judge their performance in the interview based on what the facial dectection software finds. Not only are many facial recognition technologies unethical, but margonalized people are critisized and deprived disproportionatley. Gebru mentioned a few studies that showed that displayed this behavior. First she mentioned how police in Baltimore are unethically obtaining photographs of Black protestors and using those images to arrest them for unwarranted reasons. Next she describes how black women specifically are disproportionatley mis-identified by facial recognition technologies from major tech companies such as Google and Microsoft. Through these examples, Gebru identifies how it is not just the algorithms themselves that are bias, but there is bias in the training data. It is not an AI specific problem, but a problem of who is seen and who is heard. The bottom line is the majority of data collected is on white males. She describes how in an attempt to obtain more diverse datasets, companies unethically obtain pictures and images of people. It is difficult to obtain this data in an ethical way which is where a big issue comes into play with AI and machine learning algorthims being biased due to non-diverse datasets.\n",
    "\n",
    "td;lr: Computer vision and other AI technologies have bias due to a lack of diversity in training data, and they unfairly target people who are the most margonalized and vulnerable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7ffbd-fbe7-4d2c-a310-232066414b0a",
   "metadata": {},
   "source": [
    "# Question\n",
    "What do you think is an effective and tangible step companies can take to address issues of inequality and bias in technology and machine learning programs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e327e3f-4e41-4622-a3a6-7542c093aea3",
   "metadata": {},
   "source": [
    "# Part 2: Reflecting on Gebru's Talk\n",
    "\n",
    "Dr. Gebru spoke about Eugenics and the Promise of Utopia through Artificial General Intelligence. Throughout her talk, she detailed the history of eugenics and how it isn't something that ended with WWII, but has grown and re-invented itself into new forms over the years. She describes eugenics as the idea of creating this utopia of a perfect world and perfect humans through artificial general intelligence, AGI. Most recently, Gebru describes the idea of AGI acting in this god-like sense in which AGI can solve all problems. Dr. Gebru expressed the issues and concerns she has with eugenics and the use of AGI in her talk. One of her main concerns is that all AGI research and models come from the funding of billionaires such as Elon Musk and big corporate companies. Gebru describes how these billionaires and companies not only have a monopoly on what is being researched and produced, but the datasets they use to create their models are obtained unethically. Companies are racing to create the biggest models they can and are stealing data in order to do so. Because of the corporate monopoly, resources aren't going to smaller organizations around the world that are actually producing better work. Instead, funding is going to these large companies that are trying to form this AGI utopia and they are doing subpar work. A major concern Gebru has with the idea of this AGI utopia where these machines can \"enhance transhuman minds and figure out what to do in any scenario\" is that it will only benefit the rich, high class people while continuing to leave out the marginalized. One example she gave is the potential that in the future, rich people will get to have a real doctor and poor people will have to chat with a robot if they have health concerns because they are unable to afford a real doctor. Gebru also describes how recently a halt was put on AGI because people were concerned about the dangers and possible implications of these large models that are being built. However, Gebru addresses the point that what people are failing to recognize is how we need to hold the people accountable who are creating, building and funding these systems. Instead of holding people accountable, we are being distracted by the idea of a potential sci-fi future, and we are failing to address the real problem which is the humans who are funding and building these machines. \n",
    "\n",
    "I agree with Dr. Gebru's concerns regarding AGI and the AGI utopia. Although I find the models being built incredibly interesting, I was unaware of the backstory of eugenics and the AGI utopia. I was also unaware of the centralization of power in technology and how all of the resources and funding come from these billionaires who basically get to make all of the decisions about what research is done and what models get built. I was aware of some of the unethical data collection, but I was not up to speed on everything else that goes into creating these models and all of the marginalized people that are forgotten and left behind in the process. I agree with Gebru that we need to hold the people accountable that are creating and funding these efforts, and we need to make it more accessible for smaller companies and research initiatives to get a foot in the door. Unfortunately, I do not have a solid idea of how to approach these issues. I think the most important thing people should take from Dr. Gebru's talk is that we should be more aware of the background and implications caused by applications and technologies we choose to use. As I mentioned, I was unaware of many of the unethical aspects of machine learning models that I use on a daily basis. I think by learning about and understanding the background of eugenics and how the idea of an AGI utopia is a form of eugenics, people can be more cautious about the technologies and companies they choose to use and support. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024360f-2dac-4d73-9794-8ac0a4f47534",
   "metadata": {},
   "source": [
    "# Final Reflection\n",
    "\n",
    "I am very grateful for the opportunity to listen to Dr. Gebru speak in class and during her night time talk. I learned a lot from listening to Dr. Gebru speak including aspects I was unaware of including where eugenics is currently at and the role that AGI is playing in creating said utopia and the dangers and unethical aspects that come with it. I would say prior to listening to Dr. Gebru speak, I was very naive to the issues regarding these topics. I was aware of racial and gender biases within technology, but I was unaware of the connection with eugenics and the power that billionaires hold regarding AI. I have grown a general curiosity regarding AGI and its potential implications on society after listening to Gebru speak. I want to work hard to be more aware of the choices that are being made and who is making them in the technology world as well as be more aware of how my own actions make an impact on others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
